{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stats_vs_ml_approaches_for_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVyyyK4fdWLe",
        "colab_type": "text"
      },
      "source": [
        "Traditionally statisticians and econometricians have been using statistical approaches to solve problems such as regression and classification. There are lot of similarities and differences between the statistical approach and machine learning (optimization approach [link](https://github.com/chidamnat/practicalDS/blob/master/mastery/Least_squares_regression.ipynb)).\n",
        "We have seen the bit of ML approach earlier in the link above and there are libraries such as sklearn and others. More to come on this later\n",
        "\n",
        "In this post let us take a peek into this using a popular library in python space is statsmodels which was inspired by statistical programming language R.\n",
        "\n",
        "Before getting into this there are some pre-requisites.\n",
        "\n",
        "1) [ML based approach for regression](https://github.com/chidamnat/practicalDS/blob/master/mastery/Least_squares_regression.ipynb)\n",
        "\n",
        "2) [Hypothesis Testing](https://github.com/chidamnat/practicalDS/blob/master/mastery/Test_of_hypothesis.ipynb)\n",
        "\n",
        "3) [Central Limit Theorem](https://github.com/chidamnat/practicalDS/blob/master/mastery/central_limit_theorem.ipynb) (we refer to standard_error here)\n",
        "\n",
        "Let us use the same Advertising data and see if we could predict sales based on the multiple predictors(variables) this time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZMrx2CCeuxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR6zqHigf-uw",
        "colab_type": "code",
        "outputId": "0a90190b-95b6-4c9d-a9c3-4ce3f5e39d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('Advertising.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TV</th>\n",
              "      <th>radio</th>\n",
              "      <th>newspaper</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "      <td>12.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      TV  radio  newspaper  sales\n",
              "1  230.1   37.8       69.2   22.1\n",
              "2   44.5   39.3       45.1   10.4\n",
              "3   17.2   45.9       69.3    9.3\n",
              "4  151.5   41.3       58.5   18.5\n",
              "5  180.8   10.8       58.4   12.9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V99iFVrPgeB6",
        "colab_type": "text"
      },
      "source": [
        "### Fit regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6qfFvJ-grIE",
        "colab_type": "code",
        "outputId": "72bc0b6c-07a1-40e3-b47e-7bf6df5d322d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "# Let us pick TV as a predictor to start with predicting the sales\n",
        "result1 = smf.ols('sales ~ TV ', data=df).fit()\n",
        "result1.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.612</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.610</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   312.1</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 15 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>1.47e-42</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>15:32:36</td>     <th>  Log-Likelihood:    </th> <td> -519.05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   1042.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   198</td>      <th>  BIC:               </th> <td>   1049.</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    7.0326</td> <td>    0.458</td> <td>   15.360</td> <td> 0.000</td> <td>    6.130</td> <td>    7.935</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TV</th>        <td>    0.0475</td> <td>    0.003</td> <td>   17.668</td> <td> 0.000</td> <td>    0.042</td> <td>    0.053</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td> 0.531</td> <th>  Durbin-Watson:     </th> <td>   1.935</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.767</td> <th>  Jarque-Bera (JB):  </th> <td>   0.669</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-0.089</td> <th>  Prob(JB):          </th> <td>   0.716</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.779</td> <th>  Cond. No.          </th> <td>    338.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  sales   R-squared:                       0.612\n",
              "Model:                            OLS   Adj. R-squared:                  0.610\n",
              "Method:                 Least Squares   F-statistic:                     312.1\n",
              "Date:                Sun, 15 Dec 2019   Prob (F-statistic):           1.47e-42\n",
              "Time:                        15:32:36   Log-Likelihood:                -519.05\n",
              "No. Observations:                 200   AIC:                             1042.\n",
              "Df Residuals:                     198   BIC:                             1049.\n",
              "Df Model:                           1                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      7.0326      0.458     15.360      0.000       6.130       7.935\n",
              "TV             0.0475      0.003     17.668      0.000       0.042       0.053\n",
              "==============================================================================\n",
              "Omnibus:                        0.531   Durbin-Watson:                   1.935\n",
              "Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669\n",
              "Skew:                          -0.089   Prob(JB):                        0.716\n",
              "Kurtosis:                       2.779   Cond. No.                         338.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UIlnEKyjiJg",
        "colab_type": "text"
      },
      "source": [
        "### This simple linear regression model explains 61.2% (from R-squared value) of the total variance. Which also means around 38.8% is still unexplained.\n",
        "\n",
        "We can also see that the p-value associated with this predictor (TV) on sale is close to 0. So the model is pretty confident on the estimate of this coeffient.\n",
        "\n",
        "To understand this behind the scenes, there is a [hypothesis testing](https://github.com/chidamnat/practicalDS/blob/master/mastery/Test_of_hypothesis.ipynb) involved. Null Hypothesis here is that there is no significant linear relationship between the variable TV and sales, which is coeffient (B1) is 0. After the hypothesis test is over, we see the p-value is very low and hence we reject the null hypothesis.\n",
        "\n",
        "We learnt about p-values and coefficients. What is this t-statistic?\n",
        "This is a measure of the number of standard deviations that estimate (coefficient B1 with a hat) away from zero.\n",
        "\n",
        "t = (B1_hat - 0)/ Standard_error(B1_hat).\n",
        "\n",
        "[Standard_error](https://github.com/chidamnat/practicalDS/blob/master/mastery/central_limit_theorem.ipynb) is the standard deviation of this test statistic.\n",
        "\n",
        "More the t-statistic value, farther the coefficient from 0 and unlikely the null hypothesis be True, which is good for us so we can predict the sales using TV as a predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs54Nsx4nhyY",
        "colab_type": "text"
      },
      "source": [
        "### Is this good enough ?\n",
        "let us try adding another variable radio into the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZqXsQ9qgv3D",
        "colab_type": "code",
        "outputId": "2ea03145-34a6-47b4-ddda-432cc3adb5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "source": [
        "result2 = smf.ols('sales ~ TV + radio', data=df).fit()\n",
        "result2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   859.6</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 15 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>4.83e-98</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>15:32:37</td>     <th>  Log-Likelihood:    </th> <td> -386.20</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   778.4</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th> <td>   788.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    2.9211</td> <td>    0.294</td> <td>    9.919</td> <td> 0.000</td> <td>    2.340</td> <td>    3.502</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.909</td> <td> 0.000</td> <td>    0.043</td> <td>    0.048</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>radio</th>     <td>    0.1880</td> <td>    0.008</td> <td>   23.382</td> <td> 0.000</td> <td>    0.172</td> <td>    0.204</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>60.022</td> <th>  Durbin-Watson:     </th> <td>   2.081</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 148.679</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-1.323</td> <th>  Prob(JB):          </th> <td>5.19e-33</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 6.292</td> <th>  Cond. No.          </th> <td>    425.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  sales   R-squared:                       0.897\n",
              "Model:                            OLS   Adj. R-squared:                  0.896\n",
              "Method:                 Least Squares   F-statistic:                     859.6\n",
              "Date:                Sun, 15 Dec 2019   Prob (F-statistic):           4.83e-98\n",
              "Time:                        15:32:37   Log-Likelihood:                -386.20\n",
              "No. Observations:                 200   AIC:                             778.4\n",
              "Df Residuals:                     197   BIC:                             788.3\n",
              "Df Model:                           2                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      2.9211      0.294      9.919      0.000       2.340       3.502\n",
              "TV             0.0458      0.001     32.909      0.000       0.043       0.048\n",
              "radio          0.1880      0.008     23.382      0.000       0.172       0.204\n",
              "==============================================================================\n",
              "Omnibus:                       60.022   Durbin-Watson:                   2.081\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              148.679\n",
              "Skew:                          -1.323   Prob(JB):                     5.19e-33\n",
              "Kurtosis:                       6.292   Cond. No.                         425.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA3ANVtcn7UV",
        "colab_type": "text"
      },
      "source": [
        "voila! good improvement to R-squared and now it is closer to 89.7%.\n",
        "\n",
        "Notice that the TV's coefficient estimate is smaller now than when it was used as a sole predictor. More on this later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTqUPeeqn2tl",
        "colab_type": "code",
        "outputId": "65229bee-5f1b-4391-c488-9a64f3adadc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "# Let us do all in \n",
        "\n",
        "results = smf.ols('sales ~ TV + radio + newspaper', data=df).fit()\n",
        "results.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sun, 15 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>15:32:38</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>TV</th>        <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>radio</th>     <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>newspaper</th> <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>60.414</td> <th>  Durbin-Watson:     </th> <td>   2.084</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 151.241</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td>-1.327</td> <th>  Prob(JB):          </th> <td>1.44e-33</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 6.332</td> <th>  Cond. No.          </th> <td>    454.</td>\n",
              "</tr>\n",
              "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  sales   R-squared:                       0.897\n",
              "Model:                            OLS   Adj. R-squared:                  0.896\n",
              "Method:                 Least Squares   F-statistic:                     570.3\n",
              "Date:                Sun, 15 Dec 2019   Prob (F-statistic):           1.58e-96\n",
              "Time:                        15:32:38   Log-Likelihood:                -386.18\n",
              "No. Observations:                 200   AIC:                             780.4\n",
              "Df Residuals:                     196   BIC:                             793.6\n",
              "Df Model:                           3                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      2.9389      0.312      9.422      0.000       2.324       3.554\n",
              "TV             0.0458      0.001     32.809      0.000       0.043       0.049\n",
              "radio          0.1885      0.009     21.893      0.000       0.172       0.206\n",
              "newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
              "==============================================================================\n",
              "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
              "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
              "Kurtosis:                       6.332   Cond. No.                         454.\n",
              "==============================================================================\n",
              "\n",
              "Warnings:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBkbwd3hrU2v",
        "colab_type": "text"
      },
      "source": [
        "Thats a lot of numbers. We shall understand the important ones.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "          \tcoef\t std err\tt\t    P>|t|\t[0.025\t0.975]\n",
        "Intercept\t  2.9389\t0.312\t 9.422\t0.000\t2.324\t  3.554\n",
        "TV\t        0.0458\t0.001\t32.809\t0.000\t0.043\t  0.049\n",
        "radio\t      0.1885\t0.009\t21.893\t0.000\t0.172\t  0.206\n",
        "newspaper\t -0.0010\t0.006\t-0.177\t0.860\t-0.013\t0.011\n",
        "```\n",
        "\n",
        "Here we see p-values pretty low for TV and radio. Whereas the newspaper has high p-value so newspaper is clearly insignificant or this case, we cannot reject the null hypothesis! (as statisticans say).\n",
        "\n",
        "OK. Is our model good now ?\n",
        "\n",
        "Yes. but what is the point in adding newspaper to the model when it is not adding any improvements. Sure. We can settle down with TV and radio as good predictors of sales. If I were to run any marketing campaign, I would bet on these two channels. OK, wait! How sure are you about this model if this is correct ?\n",
        "\n",
        "Well, we have explored the t-statistic and got the individual predictor p-values. Isn't that enough ?\n",
        "\n",
        "Well may be just not enough yet :)\n",
        "Why ?\n",
        "what does individual coeffient say ?\n",
        "for example, the coefficient TV as a predictor states that out of 100 times, 95 times we will observe the true coeffient of TV (which B1 without a hat!) to be in the Confidence range of [0.043\t  0.049] of B1_hat. So why is that an issue now ?\n",
        "Well there is a counter point that 5% of the time the true value will take these extreme values. So what ?\n",
        "\n",
        "Adding more variables / predictors would only compound this effect 5% * 5% * ... so on. So when more predictors are involved, individual p-value does not  give us the absolute way to evaluate our model as whole,\n",
        "\n",
        "[Savior F-statistic](https://en.wikipedia.org/wiki/Ronald_Fisher) comes to our rescue. \n",
        "F = ((TSS / RSS)/p)/(RSS/(n-p-1)))\n",
        "TSS => Total sum of squres or total variance\n",
        "RSS => unexplained sum of squares (also 1 - R-squared)\n",
        "n => number of observations\n",
        "p => number of predictors used\n",
        "\n",
        "In our case the F-statistic is 570 which is quite larger than 1. Hence we can safely conclude the null Hypothesis (B1_hat = B2_hat = ... = Bp_hat = 0) does not hold true and can be rejected.\n",
        "\n",
        "Note: when p > n, linear regression does not work with least squares method and even F-statistic wouldn't matter. In this case, we deal with this later by other means such as dimensionality reduction (more on that later).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQBH7axf2olc",
        "colab_type": "text"
      },
      "source": [
        "## Why to use linear model and when not to use it ?\n",
        "Linear model comes with linearity assumption that the true distribution is linear in nature with respect to the predictor variables.\n",
        "\n",
        "In real world mostly the linearity assumption may fail. Then why to use the linear model ? \n",
        "It is easy to explain and also not a bad model go start with unless linearity assumptions are broken. \n",
        "\n",
        "In Machine learning, there is [no free lunch theorem](https://en.wikipedia.org/wiki/No_free_lunch_theorem), which states that there is no one silver bullet model which could solve all the problems. So the problem space is quite high and to simplify this we need to make some assumptions about the world. If these assumptions are rigid, then our model may not resonate with reality (commonly called as bias). If we make the models super flexible, then it may result in complexity and overfitting (if you ask the question that model has seen, it will answer that correctly but outside this, it will have tough time). The overfitting results in high variance. So one should tradeoff between the bias and variance to build a good enough model to resonate with real system. \n",
        "\n",
        "Back to problems with linear models:\n",
        "1) Linearity assumption becomes false - what if the underlying data is not truly linear and in this case, linear model will give us a straight line and there will be high residual errors. To counter that we have options to include non-linear predictiors such as TV**2 or sqrt(TV) depending on what works best for us or to try other models such as Tree based or other non linear approaches\n",
        "\n",
        "2) error terms are correlated - Generally this is the case of timeseries data which is auto-correlated. This means that yesterday's value of a stock will determine today's stock value for example. Sometimes we see such patterns outside the timeseries data such as in survey (where same persons from a family tend to have similar food habits, which could cause some kind of unexexpected correlation). Generally [Durbin Watson](https://www.statsmodels.org/dev/generated/statsmodels.stats.stattools.durbin_watson.html) test shows if the autocorrelation in error terms is present. In our case, we have a value of 2 and hence no such issues.\n",
        "\n",
        "3) pattern in error terms - The error plot should be uniformly distributed and there should not be underlying patterns, famously called as [heteroscedasticity](https://en.wikipedia.org/wiki/Heteroscedasticity) (A tongue twister!). This can be countered by applying transformations such as log or sqrt on response variable Y (sales in this example)\n",
        "\n",
        "4) Outliers - They tend to pull the best fit line up or down. We could counter this using imputation techniques or drop these data points\n",
        "\n",
        "5) High leverage points - Extreme predictor values (example say TV or radio X values here in this problem). Sometimes this gets tricky when individually the TV or radio may not be different from the rest but a combination may be an extreme value. Can be quantified using [leverage statistic](https://stats.stackexchange.com/questions/318854/leverage-statistic-equation-explanation)\n",
        "\n",
        "6) Collinearity - If the predictors themselves are correlated to each other then the outcome cannot be easily explained by individual effect of the predictors accurately. For example, if we are interested in predicting the response variable called health_index based on height, weight and bmi, then we see the variables weight/height is highly correlated with bmi and hence makes it difficult to predict the health_index as a linear combination of these 3 predictors. To counter that we could use a correlation table to find these unwanted correlation among the predictor variables. But the problem becomes tricky if multiple variables are correlated (more than 2 variables). This is where VIF (Variance Inflation factor) comes to our rescue to detect the same. However for fixing it we need to drop one of the variables / reduce dimensionality to a much simpler representations (more on that later). \n",
        "\n",
        "We shall see how we can compute vif using statsmodels library as below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHj5Tph1rUNF",
        "colab_type": "code",
        "outputId": "36a457fa-4a12-4981-86ff-b20d96f63036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# vif example:\n",
        "from patsy import dmatrices\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import statsmodels.api as sm\n",
        "\n",
        "y, X = dmatrices(\"sales ~ TV + radio + newspaper \", data=df, return_type=\"dataframe\")\n",
        "\n",
        "# For each Xi, calculate VIF\n",
        "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# Fit X to y\n",
        "result = sm.OLS(y, X).fit()\n",
        "print(vif)\n",
        "## We are good in this case. Not much of multi-collinearity problem as the vaues are all closer to 1. \n",
        "# (high values of > 100 indicates multi-collinearity problems)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.848899953334954, 1.00461078493965, 1.1449519171055353, 1.1451873787239288]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO8WgIjFrSzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}